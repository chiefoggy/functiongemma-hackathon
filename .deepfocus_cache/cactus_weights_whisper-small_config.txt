vocab_size=51865
hidden_dim=768
num_layers=12
attention_heads=12
attention_kv_heads=12
ffn_intermediate_dim=0
context_length=0
rope_theta=10000.0
attention_head_dim=64
layer_norm_eps=1e-06
num_experts=0
num_shared_experts=0
num_top_experts=0
moe_every_n_layers=0
tie_word_embeddings=true
model_type=whisper
model_variant=default
precision=FP16
