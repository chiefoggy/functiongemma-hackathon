Orthogonal 
matrix 
 A –1 = A T 
The rows of  A  form an orthonormal basis for  Rn 
Rotation xy-
coordinates 
u is a least squares solution to Ax = b  
if and only if u is a solution to ATAx = ATb.  
The transition matrix  P  from  S  to  T  is orthogonal. 

Lecture	19	
Eigenvalues	
and	
Eigenvectors	
Example	6.1.1	
Each year  4%  of the urban population moves to the 
rural district and  1%  of the rural population moves 
to the urban district. 
We want to study the long term effect if things keep 
going like this. 
 
Let  an  and  bn  be the urban population and rural 
population, respectively, after  n  years.  
an = 0.96an–1 + 0.01bn–1  and  bn = 0.04an–1 + 0.99bn–1. 
Example	6.1.1	
Let ⎟⎠⎞⎜⎝⎛=⎟⎟⎠⎞⎜⎜⎝⎛=99.004.001.096.0Axnnnba021xAxAAxxnnnn====−−!2To study the long term effect, we need to compute  
An  for large  n. 
If possible, we want to find 0xAxnnnn∞→∞→=limlim
Example	6.1.1	
Luckily we know that 
1141195.0001141199.004.001.096.0−⎟⎠⎞⎜⎝⎛−⎟⎠⎞⎜⎝⎛⎟⎠⎞⎜⎝⎛−=⎟⎠⎞⎜⎝⎛=ALet ⎟⎠⎞⎜⎝⎛=⎟⎠⎞⎜⎝⎛−=95.00011411DPAn = (PDP 
–1)n 
     = (PDP 
–1) (PDP 
–1) ··· (PDP 
–1)     (n  times) 
     = PD P–1P D P 
–1P ··· P 
–1P DP 
–1 
= PD I D I ··· I DP 
–1 
= PD D ··· DP 
–1 
= PD 
nP 
–1 
Example	6.1.1	
⎟⎠⎞⎜⎝⎛=⎟⎟⎠⎞⎜⎜⎝⎛=⎟⎠⎞⎜⎝⎛=nnnnn95.000195.000195.0001D⎟⎠⎞⎜⎝⎛=∞→0001limnnD⎟⎠⎞⎜⎝⎛=⎟⎠⎞⎜⎝⎛−⎟⎠⎞⎜⎝⎛⎟⎠⎞⎜⎝⎛−==−−∞→∞→8.08.02.02.0141100011411limlim11PPDAnnnn
Example	6.1.1	
⎟⎟⎠⎞⎜⎜⎝⎛++=⎟⎟⎠⎞⎜⎜⎝⎛⎟⎠⎞⎜⎝⎛===⎟⎟⎠⎞⎜⎜⎝⎛∞→∞→∞→)(8.0)(2.08.08.02.02.0limlimlim000000babababannnnnn0xAxnSo in the long run, approximately  20%  of the total 
population will stay in the urban district and  80%  
of the population will stay in the rural district. 
Remark	6.1.2	
In Example 6.1.1, the crucial step of the calculation 
is to express  A  in the form  PDP 
–1  where  D  is a 
diagonal matrix. 
This leads us to the problem of “diagonalize” square 
matrices. 
First, we need to study the concept of eigenvalues 
and eigenvectors. 
Definition	6.1.3	
Let  A  be a square matrix of order  n. 
A nonzero column vector  x  in  Rn  is called an 
eigenvector of  A  if   
Ax =    x   
for some scalar     . 
The scalar       is called an eigenvalue of  A  and 
x  is said to be an eigenvector of  A  associated with 
the eigenvalue     . 
λλλλ
Example	6.1.4.1	
⎟⎠⎞⎜⎝⎛−=⎟⎠⎞⎜⎝⎛=⎟⎠⎞⎜⎝⎛=114199.004.001.096.0yxAxAx=⎟⎠⎞⎜⎝⎛=⎟⎠⎞⎜⎝⎛⎟⎠⎞⎜⎝⎛=414199.004.001.096.0yAy95.01195.095.095.01199.004.001.096.0=⎟⎠⎞⎜⎝⎛−=⎟⎠⎞⎜⎝⎛−=⎟⎠⎞⎜⎝⎛−⎟⎠⎞⎜⎝⎛=1  and  0.95  are eigenvalues of  A. 
x  is an eigenvector of  A  associated with the 
eigenvalue  1. 
y  is an eigenvector of  A  associated with the 
eigenvalue  0.95. 
Example	6.1.4.2	
⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−=⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−=⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=121101111111111111zyxB  Bx=111111111⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟111⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=333⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=3111⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=3x  By=111111111⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟10−1⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=000⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=010−1⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=0y   Bz=111111111⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟1−21⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=000⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=01−21⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=0z
Example	6.1.4.2	
3  and  0  are eigenvalues of  B. 
x  is an eigenvector of  B  associated with the 
eigenvalue  3. 
y  is an eigenvector of  B  associated with the 
eigenvalue  0. 
z  is an eigenvector of  B  associated with the 
eigenvalue  0. 
⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−−⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−−−0000000031112011111111111111112011111Note that 
Remark	6.1.5	
Let  A  be a square matrix of order  n. 
              is an eigenvalue of  A λλλλλλ⇔⇔⇔⇔⇔λλIf expanded,  det(    I – A)  is a polynomial in      of 
degree  n. 
 Ax =     x  for some nonzero column vector  x 
 x – Ax = 0  for some nonzero column vector  x 
 (    I – A) x = 0  for some nonzero column vector  x 
Ix – Ax = 0  for some nonzero column vector  x 
  det(    I – A) = 0  (see Remark 3.6.11) 
Definition	6.1.6	
Let  A  be a square matrix of order  n. 
The equation  det(    I – A) = 0  is called the 
characteristic equation of  A. 
 
The polynomial  det(    I – A)  is called the 
characteristic polynomial of  A. 
λλ
Example	6.1.7.1	
⎟⎠⎞⎜⎝⎛=99.004.001.096.0A99.004.001.096.099.004.001.096.01001det)det(−−−−=⎟⎟⎠⎞⎜⎜⎝⎛⎟⎠⎞⎜⎝⎛−⎟⎠⎞⎜⎝⎛=−λλλλAI)95.0)(1(−−=λλHence  det(     I – A) = 0  if and only if        = 1  or  0.95. 
The eigenvalues of  A  are  1  and  0.95. 
λλ =(λ−0.96)(λ−0.99)−(−0.01)(−0.04)=λ2−1.95λ+0.95
Example	6.1.7.2	
⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=111111111B233111111111)det(λλλλλλ−=−−−−−−−−−=−BI2)0)(3(−−=λλHence  det(  I – B) = 0  if and only if    = 3  or  0. 
The eigenvalues of  B  are  3  and  0. 
λλ
Example	6.1.7.3	
Hence  det(    I – C) = 0  if and only if        = 1, 2 or  3   22The eigenvalues of  C  are  1, 2 and   3.  
  C=401−210−201⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟  det(λI−C)=λ−40−12λ−1020λ−1=λ3−6λ2+11λ−6 =(λ−1)(λ−2)(λ−3)λλ
Theorem	6.1.8	
8.   rank(A) = n. 
9.   0  is not an eigenvalue of  A. 
Let  A  be a square matrix of order  n. 
The following statements are equivalent: 
1.  A  is invertible. 
2. The linear system Ax = 0 has only the trivial 
solution.  
3. The reduced row-echelon form of A is an identity 
matrix.  
4.  A can be expressed as a product of elementary 
matrices.  
5. det(A) is nonzero. 
6. The rows of  A  form a basis for  Rn. 
7. The columns of  A  form a basis for  Rn. 
Proof	of	Theorem	6.1.8	
          0  is not an eigenvalue of  A 
By Theorem 3.6.11, statements 1 to 7 are equivalent. 
By Remark 4.2.5.2, we have “5    8”.  ⇔So, we only need to show either   
“5     9”. ⇔⇔⇔⇔⇔⇔≠≠≠≠       det( 0I – A)        0    
       det( – A)        0    
       (–1)n det(A)         0    
         det(A)         0    
         A  is invertible.    
Theorem	6.1.9	
If  A  is a triangular matrix (either upper triangular 
matrix or lower triangular matrix), the eigenvalues of  
A  are the diagonal entries of  A. 
Proof	of	Theorem	6.1.9	
Suppose  A = (aij)nxn  is a triangular matrix. 
Then     I – A  is a triangular matrix with diagonal entries                                        
– a11,       – a22,  …,      – ann. 
⎟⎟⎟⎟⎟⎠⎞⎜⎜⎜⎜⎜⎝⎛−−−−−−=−⎟⎟⎟⎟⎟⎠⎞⎜⎜⎜⎜⎜⎝⎛=nnnnnnnnaaaaaaaaaaaaλλλλ002221121122211211!"##!"##AIABy Theorem 2.5.8,   
det(    I – A) = (    – a11)(     – a22)···(     – ann). 
Hence the diagonal entries,  a11, a22, …, ann,  of  A  are 
the eigenvalues of  A. 
λλλλλλλλ
Example	6.1.10	
The eigenvalues are  2,  3  and  –4. 
The eigenvalues are  1, 6  and  0. 
 2523031400−4⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟ 10036010π0⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟
Definition	6.1.11	
Let  A  be a square matrix of order  n  and  
Let   be an eigenvalue of  A. 
The solution space of the linear system  
(     I – A) x = 0 
is called the eigenspace of  A  associated with the 
eigenvalue       and is denoted by     . 
If  u  is a nonzero vector in     ,  then  u  is an 
eigenvector of  A  associated with the eigenvalue     . 
λλλλ Eλ Eλ
Example	6.1.12.1	
⎟⎠⎞⎜⎝⎛=99.004.001.096.0ABy Example 6.1.1,   
the eigenvalues of  A  are  1  and  0.95. 
Example	6.1.12.1		(Find					)	
For        = 1, 
(     I – A) x = 0 
⎟⎠⎞⎜⎝⎛=⎟⎠⎞⎜⎝⎛⎟⎠⎞⎜⎝⎛−−−−⇔0099.0104.001.096.01yx⎟⎠⎞⎜⎝⎛=⎟⎠⎞⎜⎝⎛⇔125.0tyxwhere  t  is an arbitrary parameter 
Hence 
  E1λλ  E1=span0.251⎛⎝⎜⎞⎠⎟⎧⎨⎪⎩⎪⎫⎬⎪⎭⎪
Example	6.1.12.1		(Find		E0.95)	
For      = 0.95, 
(    I – A) x = 0 
⎟⎠⎞⎜⎝⎛=⎟⎠⎞⎜⎝⎛⎟⎠⎞⎜⎝⎛−−−−⇔0099.095.004.001.096.095.0yx⎟⎠⎞⎜⎝⎛−=⎟⎠⎞⎜⎝⎛⇔11tyxwhere  t  is an arbitrary parameter 
Hence 
⎭⎬⎫⎩⎨⎧⎟⎠⎞⎜⎝⎛−=11span95.0Eλλ
Example	6.1.12.2	
⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=111111111BBy Example 6.1.4.2,   
the eigenvalues of  B  are  3  and  0. 
Example	6.1.12.2		(Find		E3)	
For      = 3, 
(    I – B) x = 0 
⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−−−−−−−−−⇔000131111311113zyx⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛⇔111tzyxwhere  t  is an arbitrary parameter 
Hence 
⎪⎭⎪⎬⎫⎪⎩⎪⎨⎧⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=111span3Eλλ
Example	6.1.12.2		(Find		E0)	
For       = 0, 
(     I – B) x = 0 
⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−−−−−−−−−⇔000101111011110zyx⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−+⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−=⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛⇔101011tszyxwhere  s, t  are arbitrary 
parameters 
Hence 
⎪⎭⎪⎬⎫⎪⎩⎪⎨⎧⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−=101,011span0Eλλ
Example	6.1.12.3	
By Example 6.1.7.3,  
the eigenvalues of  C  are  1, 2 and 3. 
  C=401−210−201⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟
Example	6.1.12.3		(Find		E1)	
For     = 1, 
(    I – C) x = 0 
where  t  is an arbitrary parameter 
Hence 
  ⇔1−40−121−10201−1⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟xyz⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=000⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟λλ  ⇔xyz⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟=t010⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟  E1=span010⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟⎧⎨⎪⎩⎪⎫⎬⎪⎭⎪
Example	6.1.12.3		(E2		and		E3	)	
Similarly, 
  E2=span−122⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟⎧⎨⎪⎩⎪⎫⎬⎪⎭⎪E3=span−111⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟⎧⎨⎪⎩⎪⎫⎬⎪⎭⎪
Example	6.1.12.4	
M  has only one eigenvalue  1. 
  E1=span10⎛⎝⎜⎞⎠⎟⎧⎨⎪⎩⎪⎫⎬⎪⎭⎪  M=1101⎛⎝⎜⎞⎠⎟
Definition	6.2.1	
A square matrix  A  is called diagonalizable if there 
exists an invertible matrix  P  such that  P 
–1AP  is a 
diagonal matrix. 
In here, the matrix  P  is said to diagonalize  A. 
Example	6.2.2.1	
⎟⎠⎞⎜⎝⎛=99.004.001.096.0A⎟⎠⎞⎜⎝⎛=⎟⎠⎞⎜⎝⎛−⎟⎠⎞⎜⎝⎛⎟⎠⎞⎜⎝⎛−−95.0001141199.004.001.096.014111A  is diagonalizable. 
Example	6.2.2.2	
⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=111111111B⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛=⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−−⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛⎟⎟⎟⎠⎞⎜⎜⎜⎝⎛−−−0000000031112011111111111111112011111B  is diagonalizable. 
Example	6.2.2.3	
M  is not diagonalizable. 
  M=1101⎛⎝⎜⎞⎠⎟
Proof	of	Example	6.2.2.3	
Assume the contrary, 
⎟⎠⎞⎜⎝⎛dcbai.e. there exists an invertible matrix               such 
that 
Then 
  abcd⎛⎝⎜⎞⎠⎟−11101⎛⎝⎜⎞⎠⎟abcd⎛⎝⎜⎞⎠⎟=λ00µ⎛⎝⎜⎞⎠⎟  1101⎛⎝⎜⎞⎠⎟abcd⎛⎝⎜⎞⎠⎟=abcd⎛⎝⎜⎞⎠⎟λ00µ⎛⎝⎜⎞⎠⎟⇒a+c=λab+d=µbc=λcd=µd⎧⎨⎪⎪⎩⎪⎪
Proof	of	Example	6.2.2.3	
Solving the equations, we obtain 
 
 
 
where  s, t  are arbitrary parameters. 
  λ=1µ=1abcd⎛⎝⎜⎞⎠⎟=st00⎛⎝⎜⎞⎠⎟  st00⎛⎝⎜⎞⎠⎟However,                 is not invertible, a contradiction. 
Learning outcomes (Section 6.1) 
(1) Why do we need to compute (high) integer powers of a 
square matrix? What is a crucial requirement if we want to 
do this computation efficiently?  
(3) (Remark 6.1.5) How to find all the eigenvalues of a 
square matrix A? What is the characteristic equation and 
characteristic polynomial of A?  
(2) What is an eigenvalue of a square matrix A? What is 
an eigenvector of A associated with the eigenvalue?  
(4) One more equivalent statement to ‘A is an invertible 
square matrix’ (in terms of eigenvalues of A).  
Learning outcomes (Section 6.2) 
(5) What are the eigenvalues of a triangular matrix?  
(6) What is the eigenspace Eλ associated with an 
eigenvalue λ of A? What does this space contain? 
(Eigenspace ⇔ Nullspace ⇔ Solution space of HLS.)  
(1) When do we say that a square matrix A is 
diagonalizable?  