Subspace 
V  = span{S} 
Contradiction with 
Theorem 3.2.9 
Solution set of 
HLS 
Linear 
dependence 
Yes 	
No 	
c1u1 + c2u2 + ··· + ckuk = 0 
Linear 
dependent 
Linear 
independent 
Non-trivial	
solution 	
trivial	
solutio
n	
Lecture	11	
Bases	
Theorem	3.4.4	
1. S  is  a linearly dependent set  if and only if at least 
one of the vectors  ui  in  S  can be written as a linear 
combination of the other vectors in  S,  i.e. 
   ui = a1u1 + a2u2 + ··· + ai–1ui–1 + ai+1ui+1 + ··· + akuk  
for some real numbers  a1, a2, …, ai–1, ai+1, …, ak; 
2. S		is	a	linearly	independent	set		if	and	only	if	no	
vector	in	S	can	be	written	as	a	linear	combination	
of	other	vectors	in	S. 
Let  S = {u1, u2, …, uk} (k    2) be a set of two or 
more vectors in  Rn. 
≥
Proof	of	Theorem	3.4.4	
Since the two statements  1  and  2  are logically 
equivalent, we only need to prove one of them. 
We shall prove the first statement. 
Proof of Theorem 3.4.4 (      ) 
Suppose  u1, u2, …, uk  are linearly dependent, 
i.e. there exist a1, a2, …, ak , not all of them are zero, 
such that  
a1u1 + a2u2 + ··· + akuk = 0 
Say,		ai		is	nonzero. 
Then 
Hence  ui  is written as a linear combination of  u1, u2, 
…, ui–1, ui+1, …, uk. 
    ui=−a1aiu1−a2aiu2−!−ai−1aiui-1−ai+1aiui+1−!−anaiun⇒
Proof of Theorem 3.4.4 (      ) 
Suppose there exists  ui  such that 
ui = a1u1 + a2u2 + ··· + ai–1ui–1 + ai+1ui+1 + ··· + akuk 
for some real numbers  a1, a2, …, ai–1, ai+1, …, ak. 
Thus 
 a1u1 + a2u2 + ··· + ai–1ui–1 – ui + ai+1ui+1 + ··· + akuk = 0. 
The equation  c1u1 + c2u2 + ··· + ckuk = 0  has nontrivial 
solution, which is  
c1 = a1,…, ci–1 = ai–1, ci = –1, ci+1 = ai+1,…, ck = ak . 
(They are not all zero.) 
So  u1, u2, …, uk  are linearly dependent. 
⇐
Remark	3.4.5	
By Theorem 3.4.4, “linearly dependent” gives us an 
explicit description of the concept of “redundancy” 
discussed in Discussion 3.4.1.  
2. If a set is linearly independent, then there is no 
“redundant” vector in the set.  
1. If a set of vectors is linearly dependent, then there 
exists at least one “redundant” vector in the set.  
Example	3.4.6.1	
For example, the vectors 
(1, 0),  (0, 1),  (1, 1) 
are linearly dependent. 
Note that (1, 1) = (1, 0) + (0, 1), 
i.e., (1, 1) is a linear combination of (1, 0) and (0, 1).  
By Theorem 3.4.4, they are linearly dependent.   
Example	3.4.6.2	
For example, the vectors 
(1, 0, 0),  (0, 1, 0),  (0, 0, 1) 
are linearly independent. 
First, a(0, 1, 0) + b(0, 0, 1) = (0, a, b,) ≠ (1, 0, 0,) , 
i.e., (1, 0, 0) can not be expressed as a linear 
combination of (0, 1, 0) and (0, 0, 1).  
Second, a(1, 0, 0) + b(0, 0, 1) = (a, 0, b) ≠ (0, 1, 0) , 
i.e., (0, 1, 0) can not be expressed as a linear 
combination of (1, 0, 0) and (0, 0, 1).  
Similarly, (0,0,1) can not be expressed as a linear 
combination of (1, 0, 0) and (0, 1, 0).  
Hence, no vector can be written as a linear combination 
of other vectors.  
By Theorem 3.4.4, they are linearly independent.   
Theorem	3.4.7	
Let  S1 = {u1, u2, …, uk}  be a set of vectors in  Rn. 
If  k > n,  then  S  is linearly dependent.  
Proof	of	Theorem	3.4.7	
Suppose  u1 = (a11, a12, …, a1n),  u2 = (a21, a22, …, a2n),  
…,  uk = (ak1, ak2, …, akn). 
Consider the equation 
c1u1 + c2u2 + ··· + ckuk = 0. 
⎪⎪⎩⎪⎪⎨⎧=+++=+++=+++000221122221121221111kknnnkkkkcacacacacacacacaca!"!!We obtain a system of  n  linear equations in variables 
c1, c2, …, ck : 
Proof	of	Theorem	3.4.7	
The system has  k  unknown  and  n  equations. 
Since  k > n,  by Remark 1.5.4.2, the system has 
nontrivial solutions. 
So  S  is linearly dependent. 
Remark 1.5.4.2: A homogeneous system of linear 
equations with more unknowns than equations has 
infinitely many solutions. 
⎟⎟⎟⎟⎟⎟⎠⎞⎜⎜⎜⎜⎜⎜⎝⎛∗⊗∗⊗∗⊗00000!"
Example	3.4.8	
1. In  R2,  a set of three or more vectors must be 
linearly dependent. 
2. In  R3,  a set of four or more vectors must be 
linearly dependent. 
Discussion	3.4.9.1	
In  R2  (or  R3),  two vectors   u  and  v  are linearly 
dependent if and only if they lie on the same line 
(when they are placed with their initial points at the 
origin).            y                           v                      u                             x      u, v  are linearly  dependent  
Discussion	3.4.9.1	
In  R2  (or  R3),  two vectors   u  and  v  are linearly 
dependent if and only if they lie on the same line 
(when they are placed with their initial points at the 
origin).            y                           v                               x       u    u, v  are linearly  dependent  
Discussion	3.4.9.1	
In  R2  (or  R3),  two vectors   u  and  v  are linearly 
independent if and only if they do not lie on the same 
line (when they are placed with their initial points at 
the origin).            y                        v                           u                             x      u, v  are linearly  independent  
Discussion	3.4.9.2	
In  R3,  three vectors   u, v  and  w  are linearly 
dependent if and only if they lie on the same plane 
(when they are placed with their initial points at the 
origin). 
                                    v                                                        the origin                                     u, v, w  are linearly dependent  (P = span{u, v, w})  
w 
u 
Discussion	3.4.9.2	
In  R3,  three vectors   u, v  and  w  are linearly 
dependent if and only if they lie on the same plane 
(when they are placed with their initial points at the 
origin). 
                                    v      P                                        w          the origin                                 u   u, v, w  are linearly dependent  (P = span{u, v, w})  
Discussion	3.4.9.2	
In  R3,  three vectors   u, v  and  w  are linearly 
independent if and only if they do not lie on the same 
plane (when they are placed with their initial points 
at the origin).                             w                                        v      P’            the origin                                 u   u, v, w  are linearly independent  (P’ = span{u, v})  
Theorem	3.4.10	
Suppose  u1, u2, …, uk  are linearly independent 
vectors in  Rn. 
Show that if  uk+1  is not a linear combination of  u1, 
u2, …, uk,  then   
u1, u2, …, uk, uk+1  are linearly independent. 
 
(This result gives us a way to add more vectors to a 
collection of linearly independent vectors.) 
Proof	of	Theorem	3.4.10	
By definition, it suffices to show the vector equation 
 c1u1 + c2u2 + ··· + ckuk + ck+1uk+1 = 0   
has only trivial solution, i.e., c1 = 0, …, ck = 0, ck+1 = 0. 
First, we show that ck+1 = 0. If it is not (ck+1  0), then 
 
     uk+1=−c1ck+1u1−c2ck+1u2−!−ckck+1uk≠which contradicts that uk+1  is not a linear combination 
of  u1, u2, …, uk.  
 
So ck+1 = 0.   
Since ck+1 = 0, we may simplify the above vector 
equation as 
c1u1 + c2u2 + ··· + ckuk + 0 = 0  
Since u1, u2, …, uk  are linearly independent, the 
vector equation has only the trivial solution, i.e.,  
c1 = 0, …, ck = 0. 
Proof	of	Theorem	3.4.10	
In sum, the only solution to the vector equation is the 
trivial solution, i.e.,  
c1 = 0,  c2 = 0, …, ck = 0, ck+1 = 0. 
It means u1, u2, …, uk, uk+1 are linearly independent. 
Discussion	3.5.1	
From now on, we shall adopt the following 
conventions in using the terms “vector space” and 
“subspace”.  
1. A set V is called a vector space if either V = Rn  or 
V is a subspace of Rn for some positive integer n.   
(In more advanced textbooks on linear algebra, “vector 
space” is defined abstractly.)  
2. Let W be a vector space. A set V is called a 
subspace of W if V is a vector space contained in W.  
Example	3.5.2	
Let U = span{(1, 1, 0)}, V = span{(0, 0, 1)} and     
W = span{(1, 0, 0), (0, 1, 0)}.  
Since U, V and W are subspaces of R3, they are 
vector spaces.  
Note that (1, 1, 0) = (1, 0, 0)+(0, 1, 0). By Theorem 
3.2.10, U    W. So U is a subspace of W.  ⊆⊄On the other hand, (0, 0, 1)   W  and hence V    W. So 
V is not a subspace of W.  
∉
Discussion	3.5.3	
Given a vector space V, we want to find a set S, as 
small as possible, so that every vector in V is a linear 
combination of the elements in S. Such a set can then  
be used to build a “coordinate system” for V.  
Definition	3.5.4	
Let  S = {u1, u2, …, uk}  be a subset of a vector 
space  V. 
Then  S  is called a basis (plural bases) for  V  if 
1.  S  is linearly independent and 
2.  S  spans  V. 
Example	3.5.5.1		Question	
Show that  S = {(1, 9, –3), (–7, 7, 10), (6, –8, –5)}  is 
a basis for  R3. 
Strategy: 
By definition, we need to prove two things: 
1. (1, 9, –3), (–7, 7, 10), (6, –8, –5)  are linearly 
independent   
2. span (S) = R3. (See Lecture 9) 
Example 3.5.5.1  Solution 
To show that  S  is linearly independent: 
c1(1, 9, –3) + c2(–7, 7, 10) + c3(6, –8, –5) = (0, 0, 0) 
                      c1 = 0,  c2 = 0  and  c3 = 0  
The system only has the trivial solution  c1 = 0,  c2 = 0  
and  c3 = 0. 
 
So  S  is linearly independent. 
  ⇒c1−7c2+6c3=09c1+7c2−8c3=0−3c1+10c2−5c3=0⎧⎨⎪⎪⎩⎪⎪⇒
Example 3.5.5.1  Solution 
To show that  span(S) = R3:  
Let  (x, y, z)  be any vector in  R3. 
(x, y, z) = c1(1, 9, –3) + c2(–7, 7, 10) + c3(6, –8, –5) 
Using Gaussian Elimination (or since the coefficient 
matrix is invertible), we find that the system is 
always consistent for any values of  x, y,  z. 
So  span (S) = R3. 
  ⇒c1−7c2+6c3=x9c1+7c2−8c3=y−3c1+10c2−5c3=z⎧⎨⎪⎪⎩⎪⎪
Example	3.5.5.1		Solution	
Since  S  are linearly independent and  span (S) = R3,  
S  is a basis for  R3. 
Example 3.5.5.2 
Let V = span{(1, 1, 0, 3), (3, 0, 1, 3), (0, 3, –1, 6)} 
and S ={(1, 1, 0, 3), (3, 0, 1, 3)}. 
Show that S is a basis for V. 
Strategy: 
By definition, we need to prove two things: 
1. (1, 1, 0, 3), (3, 0, 1, 3) are linearly independent   
2. span (S) = V. (Use Theorem 3.2.12, show that      
(0, 3, –1, 6) is a linear combination of S.) 
Example 3.5.5.2  Solution 
To show that  S  is linearly independent: 
c1(1, 1, 0, 3) + c2(3, 0, 1, 3) = (0, 0, 0) 
                      c1 = 0 and c2 = 0  
The system only has the trivial solution  c1 = 0 and  c2 = 0. 
 
So  S  is linearly independent. 
  ⇒c1+3c2=0c1=0c2=03c1+3c2=0⎧⎨⎪⎪⎩⎪⎪⇒
Example 3.5.5.2  Solution 
To show that  span(S) = V: 
Recall Theorem 3.2.12: Suppose  u1, u2, …, uk  are 
vectors taken from  Rn. 
Show that if  uk  is a linear combination of  u1, u2, …, 
uk–1,  then 
span{u1, u2, …, uk–1} = span{u1, u2, …, uk}. 
We need to show that 
span{(1, 1, 0, 3), (3, 0, 1, 3)} = span{(1, 1, 0, 3), (3, 
0, 1, 3), (0, 3, –1, 6)} 
Note that (0, 3, –1, 6) = 3(1, 1, 0, 3)–(3, 0, 1, 3). 
So span(S) = V by Theorem 3.2.12. 
Example	3.5.5.2		Solution	
Since  S  are linearly independent and  span (S) = V,  
S  is a basis for  V. 
Example 3.5.5.3 
Is  S = {(1, 2, 3, 4), (–1, 0, 1, 0), (2, 3, 0, 1)}  a basis 
for  R4 ? 
Ans: By Theorem 3.2.7,  span(S)      R4, ≠Recall Theorem 3.2.7: Let S = {u1, u2 , … , uk} be a 
set of vectors in Rn. If k<n, then S can not span Rn.  
e.g.  The vector  (0, 0, 0, 1)  is not a linear combination 
of (1, 2, 3, 4), (–1, 0, 1, 0), (2, 3, 0, 1). 
 
So  S  is not a basis for  R4. 
Example	3.5.5.4	
Is  S = {(1, 1, 0), (1, 0, 0), (0, 1, 0)}  a basis for  R3 ? 
Note that  S  is linearly dependent, 
e.g.  (1, 1, 0) = (1, 0, 0) + (0, 1, 0). 
 
So  S  is not a basis for  R3. 
Remark	3.5.6	
3. Except the zero space, any vector space has 
infinitely many different bases. 
2. For convenience, we say that the empty set,    , is 
the basis for the zero space.  
1. A basis for a vector space  V  contains the smallest 
possible number of vector that can span  V. 
∅
Theorem	3.5.7	
Let  S = {u1, u2, …, uk}  be a basis for a vector space  
V. 
Every vector  v  in  V  can be expressed in the form 
v = c1u1 + c2u2 + ··· + ckuk 
in exactly one way, where  c1, c2, …, ck  are real 
numbers. 
Proof	of	Theorem	3.5.7	
Since  S  spans  V,  every vector  v  in  V  can be 
expressed in the form  v = c1u1 + c2u2 + ··· + ckuk. 
Suppose a vector  v  in  V  can be expressed in two ways: 
v = c1u1 + c2u2 + ··· + ckuk 
v = d1u1 + d2u2 + ··· + dkuk 
where  c1, c2, …, ck, d1, d2, …, dk  are real numbers. 
Then  (c1 –  d1)u1 + (c2 –  d2)u2 + ··· + (ck –  dk) uk = 0. 
Since  S  is linearly independent, the only possible 
solution is  c1 –  d1 = 0,  c2 –  d2 = 0,  …,  ck –  dk = 0, 
i.e.  c1 = d1,  c2 = d2,  …,  ck = dk. 
So the expression is unique. 
Learning outcomes (Section 3.4) 
(4)  If {u1, u2, …, uk} is a linearly independent set, how 
can we choose a uk+1 such that {u1, u2, …, uk, uk+1} 
remains a linearly independent set?  
(3) (Theorem 3.4.7) If S is a set of k>n vectors in Rn, then 
S is always linearly dependent.   
Learning outcomes (Section 3.5) 
(1)  Conventions in using the terms ‘vector space’ and 
‘subspace’.  
(4) (Theorem 3.5.7) The unique representation of a vector 
v (belonging to V ) in terms of a set of basis vectors for V.  
(2)  Motivation: Given a vector space V, we want to find a 
set S, as small as possible so that every vector in V is a 
linear combination of the elements in S.  
(3)  Definition of a basis for a vector space (in terms of 
linear span and linear independence).  