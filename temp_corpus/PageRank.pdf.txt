Page Rank
1
1 2 3
4 5 6
Webpage
2
Definition (Adjacency matrix)Define the adjacency matrix of a webgraph with n pages to be the nnmatrix Awhose ijth entry aij
3
=1if the jth page has an outgoing link to the ith page 
and 0otherwise. j i
4
Page 1Page 2Page 3Page 4Page 5Page 6Page 1Page 2Page 3Page 4Page 5Page 6
Adjacency Matrix
The first row a1j: 1if the jthpage has an outgoing link to the 1stpage and 0otherwise. 
1 2 3
4 5 6
Webpage
5
6
Page 1Page 2Page 3Page 4Page 5Page 6Page 1010011Page 2Page 3Page 4Page 5Page 6
Next, we fill up the 6th row a6j: 1if the jthpage has an outgoing link to the 6thpage and 0otherwise. 
1 2 3
4 5 6
Webpage
7
8
Page 1Page 2Page 3Page 4Page 5Page 6Page 1010011Page 2Page 3Page 4Page 5Page 6001110
Exercise.Fill up all the rest entries.
9
Page 1Page 2Page 3Page 4Page 5Page 6Page 1010011Page 2001010Page 3100101Page 4010001Page 5011000Page 6001110
 010011001010100101010001011000001110⎛⎝⎜⎜⎜⎜⎜⎜⎞⎠⎟⎟⎟⎟⎟⎟Adjacencymatrix
10
The sum of the entries in the jthcolumnis the number of outgoinglinks on the jthpageto other pages.
Discussion
Page 1Page 2Page 3Page 4Page 5Page 6Page 1010011Page 2001010Page 3100101Page 4010001Page 5011000Page 6001110Sum133233
1 2 3
4 5 6
The sum of the entries in the 3rd columnis 3.
Definition (State vector)If a webgraph with npages is “surfed” by clicking a mouse, then the statevectorx(k)is the n 1column vectorwhose ith entryis the probabilitythat the surfer is on the ith page after krandom mouse clicks. 
  x(0)=010000⎛⎝⎜⎜⎜⎜⎜⎜⎜⎞⎠⎟⎟⎟⎟⎟⎟⎟         Ax(0)=010011001010100101010001011000001110⎛⎝⎜⎜⎜⎜⎜⎜⎜⎞⎠⎟⎟⎟⎟⎟⎟⎟010000⎛⎝⎜⎜⎜⎜⎜⎜⎜⎞⎠⎟⎟⎟⎟⎟⎟⎟=100110⎛⎝⎜⎜⎜⎜⎜⎜⎜⎞⎠⎟⎟⎟⎟⎟⎟⎟
13
DefinitionThe stochastic matrix B = (bij)associated with an adjacency matrix A = (bij)is the matrix obtained by dividing each entry of Aby the sum of the entries in the same column; that is, 
  bij=aijakjk=1n∑
14
  B=01/3001/31/3001/301/301001/201/301/30001/301/31/3000001/31/31/30⎛⎝⎜⎜⎜⎜⎜⎜⎜⎞⎠⎟⎟⎟⎟⎟⎟⎟  x(1)=Bx(0)=1/3001/31/30⎛⎝⎜⎜⎜⎜⎜⎜⎜⎞⎠⎟⎟⎟⎟⎟⎟⎟   x(k)=Bx(k−1)      limk→∞x(k)=limk→∞Bx(k−1)=limk→∞B(k)x(0)=???
15
10.20 Internet Search Engines 709
Y ou should be able to see that 0 ≤bij≤1 and that the entries in each column of Bsum
up to 1. As an example, the probability transition matrix associated with (2) is
B=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
01 /30 01 /31 /3
001 /301 /30
10 01 /201 /3
01 /30 0 01 /3
01 /31 /30 0 0
001 /31 /21 /30
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
(3)
This matrix incorporates the probability information for advancing randomly from one
page to the next with a mouse click. For example, if we know with certainty that Alice
is initially on Page 2, then her initial state vector is
x(0)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0
1
0
0
0
0
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
Her state vector to four decimal places after one mouse click will be
x(1)
=Bx(0)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
01 /30 01 /31 /3
001 /301 /30
10 01 /201 /3
01 /30 0 01 /3
01 /31 /30 0 0
001 /31 /21 /30
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0
1
0
0
0
0
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
1/3
0
0
1/3
1/3
0
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
≈
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.3333
0
0
0.3333
0.3333
0
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
and her state vectors resulting from successive mouse clicks will form the sequence
x(k)
=Bx(k−1)
,k =1,2,3,... (4)
It follows from this that her successive state vectors rounded to four decimal places will
be
x(0)=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0
1
0
0
0
0
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(1)=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.3333
0
0
0.3333
0.3333
0
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(2)=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1111
0.1111
0.5000
0
0
0.2778
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(3)=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1296
0.1667
0.2037
0.1296
0.2037
0.1667
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
,
x(5)=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1533
0.1245
0.3014
0.1121
0.1286
0.1800
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(10)=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1562
0.1366
0.2700
0.1101
0.1366
0.1905
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(15)=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1544
0.1365
0.2727
0.1090
0.1365
0.1910
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
lim
k!1
Bk
x(0)
=
0
B
B
B
B
B
B
@
17
110
3
22
3
11
6
55
3
22
21
110
1
C
C
C
C
C
C
A
⇡
0
B
B
B
B
B
B
@
0.154545
0.1363636
0.272727
0.109091
0.136364
0.190909
1
C
C
C
C
C
C
A
2
Eigenvector in E1
Page 1Page 2Page 3Page 4Page 5Page 6
16
EigenvectorWebpage0.154545Page 10.1363636Page 20.272727Page 30.109091Page 40.136364Page 50.190909Page 6
DecreasingRank0.272727Page 30.190909Page 60.154545Page 10.1363636Page 20.136364Page 50.109091Page 4361254
Internet SearchEngines
17
710 Chapter 10 Applications of Linear Algebra
Eigenvector of the
T ransition Matrix
If we accept that the state vector x(k)
approaches a limit xas k(the number of mouse
clicks) increases without bound, then it follows from (4) that
x=Bx (5)
That is, xis an eigenvector of Bcorresponding to the eigenvalue 1. If xis scaled so that
its entries sum to 1, then the entries of xcan be interpreted as the fraction of times that
we can expect each page to be visited as the number of mouse clicks increases without
bound. For example, with the help of a computer algebra system such as MATLAB ,
Mathematica , or Maple one can show that for the matrix Bin (3) such an eigenvector is
x=
1
110
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
17
15
30
12
15
21
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
≈
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1545
0.1364
0.2727
0.1091
0.1364
0.1909
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
Compare this to the results that Alice obtained in Table 2.
Bob’ s Strategy Although Bob agrees with Alice’s deﬁnition of page rank, he realizes that it can be
misleading for certain webgraphs. For example, in Figure 10.20.2 athe webgraph consists
of two unlinked page clusters. In this case should the initial state vector have zero
probabilities for all of the pages in one of the clusters, then so will all subsequent state
vectors so that no pages in that cluster will ever be accessed. A more subtle example is
illustrated in Figure 10.20.2 b. In this case the cluster of Pages 1, 2, and 3 has no outgoing
links to the cluster of Pages 4, 5, and 6, so once a surfer exits cluster 4, 5, 6 the surfer
will be “trapped” in cluster 1, 2, 3 and the fractional page counts for Pages 4, 5, and 6
will approach zero, thereby assigning the pages in that cluster a page rank of 0.
Figure 10.20.2
1
4
2
5
3
6
1
4
2
5
3
6
(a) (b)
Bob’s solution to this problem is to assume that he is not required to follow only
the links on his current page but can with a certain probability choose any page in the
network to go to next. Speciﬁcally, Bob assumes that there is a probability of δ, called
the damping factor , that he will go to the next page by choosing a link on the current
page and a probability of 1 −δthat he will choose the next page at random. If there
are npages in the network, then in the latter case the probability that he will choose any
particular page at random is
1−δ
n
10.20 Internet Search Engines 71 1
T o implement his strategy Bob creates a new probability transition matrix M=[mij]in
which
mij =δbij+
1−δ
n
(6)
with bijas given in Deﬁnition 2. He then replaces (4) with the iterative scheme
x(k)
=Mx(k−1)
,k =1,2,3,... (7)
In Exercise 4 we will ask you to show that Mis a probability transition matrix; that
is, its entries are nonnegative and the entries in each column sum to 1. W e will also ask
you to show that Mcan be written as
M=δB+
1−δ
n
⎡
⎢
⎢
⎢
⎢
⎣
11 ··· 1
11 ··· 1
...
...
...
...
11 ··· 1
⎤
⎥
⎥
⎥
⎥
⎦
(8)
with Bas given in Deﬁnition 2. It follows from this that the iterative scheme in (7) can
be written in the form
x(k)
=δBx(k−1)
+
1−δ
n
⎡
⎢
⎢
⎢
⎢
⎣
1
1
...
1
⎤
⎥
⎥
⎥
⎥
⎦
(9)
As an example, consider the webgraph in Figure 10.20.2 b. Its adjacency matrix and
accompanying transition matrix are
A=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
010011
001011
110101
000001
000000
000110
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
and B=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
01 /20 0 1 /31 /4
00101 /31 /4
11 /201 /201 /4
0000 01 /4
0000 0 0
000 1 /21 /30
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
As is common, we will choose an initial state vector in which all entries are equal:
x(0)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
1/6
1/6
1/6
1/6
1/6
1/6
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
Alice’s iterative strategy x(k+1)=Bx(k) yields
x(0)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1667
0.1667
0.1667
0.1667
0.1667
0.1667
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(5)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1999
0.4043
0.3930
0.0007
0.0000
0.0022
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(10)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1992
0.4015
0.3992
0.0000
0.0000
0.0000
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(15)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1998
0.4002
0.4000
0.0000
0.0000
0.0000
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
10.20 Internet Search Engines 71 1
T o implement his strategy Bob creates a new probability transition matrix M=[mij]in
which
mij =δbij+
1−δ
n
(6)
with bijas given in Deﬁnition 2. He then replaces (4) with the iterative scheme
x(k)
=Mx(k−1)
,k =1,2,3,... (7)
In Exercise 4 we will ask you to show that Mis a probability transition matrix; that
is, its entries are nonnegative and the entries in each column sum to 1. W e will also ask
you to show that Mcan be written as
M=δB+
1−δ
n
⎡
⎢
⎢
⎢
⎢
⎣
11 ··· 1
11 ··· 1
...
...
...
...
11 ··· 1
⎤
⎥
⎥
⎥
⎥
⎦
(8)
with Bas given in Deﬁnition 2. It follows from this that the iterative scheme in (7) can
be written in the form
x(k)
=δBx(k−1)
+
1−δ
n
⎡
⎢
⎢
⎢
⎢
⎣
1
1
...
1
⎤
⎥
⎥
⎥
⎥
⎦
(9)
As an example, consider the webgraph in Figure 10.20.2 b. Its adjacency matrix and
accompanying transition matrix are
A=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
010011
001011
110101
000001
000000
000110
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
and B=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
01 /20 0 1 /31 /4
00101 /31 /4
11 /201 /201 /4
0000 01 /4
0000 0 0
000 1 /21 /30
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
As is common, we will choose an initial state vector in which all entries are equal:
x(0)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
1/6
1/6
1/6
1/6
1/6
1/6
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
Alice’s iterative strategy x(k+1)=Bx(k) yields
x(0)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1667
0.1667
0.1667
0.1667
0.1667
0.1667
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(5)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1999
0.4043
0.3930
0.0007
0.0000
0.0022
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(10)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1992
0.4015
0.3992
0.0000
0.0000
0.0000
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(15)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1998
0.4002
0.4000
0.0000
0.0000
0.0000
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
Another Example
18
Damping factorDefine a new probability transition matrix 
Here                is a constant (close to 1) and called damping factor.    M=δB+1−δn11!111!1""#"11!1⎛⎝⎜⎜⎜⎜⎞⎠⎟⎟⎟⎟ 0<δ<1For example, we can take   δ=0.85,……,0.90
19
lim
k!1
Bk
x(0)
=
0
B
B
B
B
B
B
@
17
110
3
22
3
11
6
55
3
22
21
110
1
C
C
C
C
C
C
A
⇡
0
B
B
B
B
B
B
@
0.154545
0.1363636
0.272727
0.109091
0.136364
0.190909
1
C
C
C
C
C
C
A
M=0.85B+
1 0.85
6
0
B
B
B
B
B
B
@
0.025 0 .45 0 .025 0 .025 0 .308333 0 .2375
0.025 0 .025 0 .875 0 .025 0 .308333 0 .2375
0.875 0 .45 0 .025 0 .45 0 .025 0 .2375
0.025 0 .025 0 .025 0 .025 0 .025 0 .2375
0.025 0 .025 0 .025 0 .025 0 .025 0 .025
0.025 0 .025 0 .025 0 .45 0 .308333 0 .025
1
C
C
C
C
C
C
A
lim
k!1
Mk
x(0)
⇡
0
B
B
B
B
B
B
@
0.189173
0.346149
0.357752
0.0349765
0.025
0.0469484
1
C
C
C
C
C
C
A
2
Remark.The introduction of a damping factor was the main innovation of the PageRank algorithmused by the Google search engine. 
Using Mto replace Bwill address our issues, and then compute      limk→∞x(k)=limk→∞Mx(k−1)=limk→∞M(k)x(0)=??? δ=0.85Take
20
Theoretical Reasons.Damping factor guarantees that every entry is strictly positive (no zero entries). Then, we can show that: For the initial state vecotr x(0)= (x1, x2, …xn)T,If  x1 + x2+ …+ xn=1 (all xinon-negative), then
the eigenvector uassociated to eigenvalue 1and satisfying u1 + u2+ …+ un=1     limk→∞Mkx(0)=u=(u1,u2,…un)
21
712 Chapter 10 Applications of Linear Algebra
By comparison, when Bob implements his revised iterative scheme beginning with the
same initial page state vector but with δ=0.85, he obtains
x(0)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1667
0.1667
0.1667
0.1667
0.1667
0.1667
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(5)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1891
0.3480
0.3550
0.0352
0.0250
0.0477
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(10)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1890
0.3464
0.3576
0.0350
0.0250
0.0469
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
, x(15)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
0.1892
0.3462
0.3578
0.0350
0.0250
0.0469
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
From these computations we see that whereas Alice’s scheme leads to ranks of 0 for
Pages 4, 5, and 6, Bob’s strategy leads to more reasonable nonzero ranks for these pages.
Mathematically, including a damping factor δ(0≤δ<1)ensures that the matrix
Mis regular (Deﬁnition 2 of Section 5.5 or Deﬁnition 3 of Section 10.4) and that for any
normalized initial state vector the iterates x(k)
converge to an eigenvector with positive
entries and which corresponds to the eigenvalue 1 (Theorem 5.5.1 or Theorem 10.4.3).
A Final Note Although Markov chain theory had long been used in ranking nodes of networks, the
introduction of a damping factor was the main innovation of the PageRank algorithm
used by the Google search engine. This algorithm is named for Larry Page who, along
with Sergey Brin, founded the Google company in the late 1990s.
Exercise Set 10.20
1.Without damping, ﬁnd the page ranks of the following web-
graphs of three pages by determining their normalized eigen-
vectors for the eigenvalue 1.
1
1
2
2
3
3
(a)
(b)
Figure Ex-1
2.Show that starting with an initial state vector with equal en-
tries in the iterative scheme x(k)
=Mx(k−1)
is equivalent to
averaging the iterates obtained by starting with each of the
pages in the webgraph individually .
3.Show that if every page in a webgraph is linked to every other
page, then all the pages have the same rank for any damping
factor δin[0,1].
4.Show that the matrix Min Equation (7) is a transition matrix;
that is, its entries are nonnegative and its column sums are all
equal to 1. Also show that Mcan be written as in Equation (8).
5.Show that iteration scheme x(k)
=Mx(k−1)
in Equation (7)
with the damping factor δcan be written as in Equation (9).
6.A dangling page (one with no outgoing links) can be dealt with
by inserting virtual links to all of the pages in the webgraph,
including itself. How does this change the adjacency matrix
and the transition matrix for any damping factor δ?
7.Suppose a webgraph has only two pages and each page has a
link to the other.
(a) Without damping (Alice’s strategy), ﬁnd the eigenvalues
of the transition matrix and the eigenvector for the eigen-
value 1. Show that if the initial page state vector is
x(0)
=[10 ]T
, the iteration scheme x(k)
=Bx(k−1)
does
not converge. However, show that the fractional page
count converges to [1/21 /2]T
.
(b) With damping δin[0,1)(Bob’s strategy), ﬁnd the eigen-
values of the transition matrix and the eigenvector for the
eigenvalue 1. Show that for any initial page state vector x(0)
the iteration scheme x(k)
=Mx(k−1)
converges. Do this by
ﬁnding an explicit expression for Mk
fork=1,2,....
8.By using the fact that a matrix and its transpose have the same
set of eigenvalues, show that any transition probability matrix
(a square matrix with nonnegative entries, all of whose column
sums are 1) has the eigenvalue 1.
lim
k!1
Bk
x(0)
=
0
B
B
B
B
B
B
@
17
110
3
22
3
11
6
55
3
22
21
110
1
C
C
C
C
C
C
A
⇡
0
B
B
B
B
B
B
@
0.154545
0.1363636
0.272727
0.109091
0.136364
0.190909
1
C
C
C
C
C
C
A
M =0.85B+
1 0.85
6
0
B
B
B
B
B
B
@
0.025 0 .45 0 .025 0 .025 0 .308333 0 .2375
0.025 0 .025 0 .875 0 .025 0 .308333 0 .2375
0.875 0 .45 0 .025 0 .45 0 .025 0 .2375
0.025 0 .025 0 .025 0 .025 0 .025 0 .2375
0.025 0 .025 0 .025 0 .025 0 .025 0 .025
0.025 0 .025 0 .025 0 .45 0 .308333 0 .025
1
C
C
C
C
C
C
A
lim
k!1
Mk
x(0)
⇡
0
B
B
B
B
B
B
@
0.189173
0.346149
0.357752
0.0349765
0.025
0.0469484
1
C
C
C
C
C
C
A
2
   Mkx(0)Page 1Page 2Page 3Page 4Page 5Page 6
Compute
Eigenvector in E1
22
EigenvectorWebpage0.189173Page 10.346149Page 20.357752Page 30.0349765Page 40.025Page 50.0469484Page 6
DecreasingRank0.357752Page 30.346149Page 20.189173Page 10.0469484Page 60.0349765Page 40.025Page 5321645
PageRankAlgorithm